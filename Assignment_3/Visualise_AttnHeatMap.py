"""
Visualise Attention HeatMap generated by Model
"""

# Imports


from Model import *

# Main Functions
def Vis_AttnHeatMap(model, dataset, dataset_encoded, n=9):
    '''
    Visualise Attention HeatMap generated by Model
    '''
    # Get Test Dataset
    DATASET_TEST, DATASET_ENCODED_TEST = dataset, dataset_encoded
    # Get Encoder Decoder Models
    params = {
        "target_chars": DATASET_ENCODED_TEST["chars"]["target_chars"],
        "target_char_map": DATASET_ENCODED_TEST["chars"]["target_char_map"]
    }
    params["use_attention"] = "attention" in [layer.name for layer in model.layers]
    encoder_model, decoder_model = Model_Inference_GetEncoderDecoder(model, **params)
    # Get Encoder Decoder Inputs
    dataset_test_encoder_input = np.argmax(DATASET_ENCODED_TEST["encoder_input"], axis=-1)

    # Get Random Test Samples
    random_indices = [np.random.randint(0, dataset_test_encoder_input.shape[0]) for i in range(n)]
    fig = plt.figure(figsize=(10, 10))
    subplot_i = 1
    for i in random_indices:
        query = dataset_test_encoder_input[i:i+1]
        decoded_word, attention = Model_Inference_Transliterate(query, encoder_model, decoder_model, **params)
        decoded_word = decoded_word[0]
        attention = np.array(attention)
        attention = attention.reshape((attention.shape[0], attention.shape[-1]))
        # Pad to fit
        input_word = DATASET_TEST["input"][i]
        word_max_size = max(len(decoded_word), len(input_word))
        decoded_word = list(decoded_word) + [""] * (word_max_size - len(decoded_word))
        input_word = list(input_word) + [""] * (word_max_size - len(input_word))
        attention = attention[:word_max_size, 1:word_max_size] # Skip Start Symbol for Input word
        # Plot
        nCols = int(n ** (0.5))
        nRows = int(np.ceil(n/nCols))
        plt.subplot(nRows, nCols, subplot_i)
        plt.imshow(attention, cmap="Blues")
        plt.xticks(range(len(decoded_word)), input_word)
        plt.yticks(range(len(decoded_word)), decoded_word, fontproperties=FontProperties(fname=FONT_PATH_TAMIL))
        subplot_i += 1
    plt.savefig("Outputs/Attention_HeatMap.png")
    # plt.show()

# Run